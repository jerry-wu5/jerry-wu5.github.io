[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jerry Wu",
    "section": "",
    "text": "Current\n\nMSBA Student | UC San Diego Rady School of Management\nAspiring Data Scientist | Tech & Healthcare\nBusiness Analytics Enthusiast\n\n\n\n\nEducation\n\nMS in Business Analytics | UCSD Rady | 2025\nBS in Management Science, Minor in Data Science | UCSD | 2024"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "This is Project 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nJerry Wu\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/project1/index.html",
    "href": "blog/project1/index.html",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data"
  },
  {
    "objectID": "blog/project1/index.html#section-1-data",
    "href": "blog/project1/index.html#section-1-data",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data"
  },
  {
    "objectID": "blog/project1/index.html#section-2-analysis",
    "href": "blog/project1/index.html#section-2-analysis",
    "title": "This is Project 1",
    "section": "Section 2: Analysis",
    "text": "Section 2: Analysis\nI analyzed the data\n\nprint (\"Hello World\")\n\nHello World"
  },
  {
    "objectID": "blog/hw1/hw1_questions.html",
    "href": "blog/hw1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe study was a natural field experiment involving 50,083 past donors to a U.S.-based civil liberties nonprofit. Participants were randomly assigned to either a control group (receiving a standard fundraising appeal) or a treatment group (receiving a letter mentioning a matching grant offer). Within the treatment group, participants were further randomly assigned to sub-treatments varying the matching ratio ($1:$1, $2:$1, $3:$1), the maximum match amount ($25,000, $50,000, $100,000, or unstated), and the suggested donation (“ask amount”) (equal to prior gift, 1.25×, or 1.5×). The experiment tested whether these pricing manipulations influenced donor behavior. While offering any match increased response rates and revenue per solicitation, larger match ratios did not produce statistically significant differences in giving. The study also explored how effects varied by geography and found greater responsiveness in “red” states (which had voted for George W. Bush in 2004). This nuanced field experiment contributed robust evidence to the demand-side economics of charitable giving.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/hw1/hw1_questions.html#introduction",
    "href": "blog/hw1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe study was a natural field experiment involving 50,083 past donors to a U.S.-based civil liberties nonprofit. Participants were randomly assigned to either a control group (receiving a standard fundraising appeal) or a treatment group (receiving a letter mentioning a matching grant offer). Within the treatment group, participants were further randomly assigned to sub-treatments varying the matching ratio ($1:$1, $2:$1, $3:$1), the maximum match amount ($25,000, $50,000, $100,000, or unstated), and the suggested donation (“ask amount”) (equal to prior gift, 1.25×, or 1.5×). The experiment tested whether these pricing manipulations influenced donor behavior. While offering any match increased response rates and revenue per solicitation, larger match ratios did not produce statistically significant differences in giving. The study also explored how effects varied by geography and found greater responsiveness in “red” states (which had voted for George W. Bush in 2004). This nuanced field experiment contributed robust evidence to the demand-side economics of charitable giving.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/hw1/hw1_questions.html#data",
    "href": "blog/hw1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport pandas as pd\ndf = pd.read_stata('karlan_list_2007.dta')\ndf.describe()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio2\nratio3\nsize25\nsize50\nsize100\nsizeno\naskd1\naskd2\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n0.222311\n0.222211\n0.166723\n0.166623\n0.166723\n0.166743\n0.222311\n0.222291\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n0.415803\n0.415736\n0.372732\n0.372643\n0.372732\n0.372750\n0.415803\n0.415790\n...\n0.499900\n0.499878\n0.168561\n0.135868\n0.103039\n0.378115\n22027.316665\n0.193405\n0.186599\n0.258654\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 48 columns\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nimport numpy as np\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LinearRegression\nfrom scipy import stats\n\ntest_vars = ['mrm2', 'couple', 'female', 'ave_hh_sz']\nresults = {}\n\nfor var in test_vars:\n    df_clean = df[['treatment', 'control', var]].dropna()\n\n    treatment_group = df_clean[df_clean['treatment'] == 1][var]\n    control_group = df_clean[df_clean['control'] == 1][var]\n\n    # Manual t-test\n    mean_diff = treatment_group.mean() - control_group.mean()\n    n1, n2 = len(treatment_group), len(control_group)\n    var1, var2 = treatment_group.var(ddof=1), control_group.var(ddof=1)\n    se = np.sqrt(var1 / n1 + var2 / n2)\n    t_stat = mean_diff / se\n    df_denom = (var1 / n1 + var2 / n2) ** 2\n    df_num = (var1**2) / (n1**2 * (n1 - 1)) + (var2**2) / (n2**2 * (n2 - 1))\n    df_ttest = df_denom / df_num\n    p_value_ttest = 2 * (1 - stats.t.cdf(np.abs(t_stat), df_ttest))\n    # Linear regression\n    X = sm.add_constant(df_clean['treatment'])\n    y = df_clean[var]\n    model = sm.OLS(y, X).fit()\n    coef = model.params['treatment']\n    p_value_reg = model.pvalues['treatment']\n    print(\"================================================\")\n    print(f'{var} Analysis: \\n')\n    print(f'{var} Treatment mean: {treatment_group.mean()}')\n    print(f'{var} Control mean: {control_group.mean()}')\n    print(f'{var} All Mean: {df_clean[var].mean()}')\n    print('________________________________________________')\n    print('t-test: \\n')\n    print(f't-statistic: {t_stat}')\n    print(f'p-value: {p_value_ttest}')\n    print('________________________________________________')\n    print('Linear Regression: \\n')\n    print(f'Coefficient on Treatment: {coef}')\n    print(f'p-value: {p_value_reg}\\n')\n\n================================================\nmrm2 Analysis: \n\nmrm2 Treatment mean: 13.011828117981734\nmrm2 Control mean: 12.99814226643495\nmrm2 All Mean: 13.00726808034823\n________________________________________________\nt-test: \n\nt-statistic: 0.1195315522817725\np-value: 0.9048549631450833\n________________________________________________\nLinear Regression: \n\nCoefficient on Treatment: 0.013685851546779986\np-value: 0.904885973177816\n\n================================================\ncouple Analysis: \n\ncouple Treatment mean: 0.09135794896957802\ncouple Control mean: 0.0929748269737245\ncouple All Mean: 0.0918974149381833\n________________________________________________\nt-test: \n\nt-statistic: -0.5822577486767693\np-value: 0.5603971270058028\n________________________________________________\nLinear Regression: \n\nCoefficient on Treatment: -0.0016168780041463048\np-value: 0.5593646446996638\n\n================================================\nfemale Analysis: \n\nfemale Treatment mean: 0.2751509208469954\nfemale Control mean: 0.2826978395250627\nfemale All Mean: 0.27766887200849466\n________________________________________________\nt-test: \n\nt-statistic: -1.7535132542519636\np-value: 0.07952338672686232\n________________________________________________\nLinear Regression: \n\nCoefficient on Treatment: -0.007546918678066679\np-value: 0.07869095826986866\n\n================================================\nave_hh_sz Analysis: \n\nave_hh_sz Treatment mean: 2.4300146102905273\nave_hh_sz Control mean: 2.427002429962158\nave_hh_sz All Mean: 2.4290122985839844\n________________________________________________\nt-test: \n\nt-statistic: 0.8233500123023987\np-value: 0.4103151242417935\n________________________________________________\nLinear Regression: \n\nCoefficient on Treatment: 0.003012174284715988\np-value: 0.409801160289328\n\n\n\nTo assess the randomization, I tested several baseline variables (e.g., months since last donation, gender, couple status, average household size within zip) using both t-tests and linear regressions and in every case the results from the two methods were nearly identical. None of the variables showed statistically significant differences at the 95% level, confirming balance between treatment and control groups. This supports the validity of the randomization and mirrors the role of Table 1 in the paper, which demonstrates baseline equivalence."
  },
  {
    "objectID": "blog/hw1/hw1_questions.html#experimental-results",
    "href": "blog/hw1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib.pyplot as plt\ndf_bar = df[['treatment', 'control', 'gave']].dropna()\n\ndf_bar['group'] = df_bar.apply(lambda row: 'Treatment' if row['treatment'] == 1 else 'Control', axis=1)\n\ndonation_rates = df_bar.groupby('group')['gave'].mean()\n\nplt.figure(figsize=(6, 5))\nax = donation_rates.plot(kind='bar')\n\nfor i, value in enumerate(donation_rates):\n    ax.text(i, value + 0.0001, f'{value:.3f}', ha='center', va='bottom')\nplt.ylabel('Proportion Donated')\nplt.title('Donation Rate by Group')\nplt.ylim(0, 0.03)\nplt.xticks(rotation=0)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe bar plot compares donation rates between the treatment and control groups. The treatment group, which received a matching donation offer, had a higher donation rate (2.2%) than the control group (1.8%). This visual evidence suggests that the presence of a matching grant increased the likelihood of donating, consistent with the main findings in the paper.\n\nimport numpy as np\nimport statsmodels.api as sm\nfrom scipy import stats\n\ndf_binary = df[['treatment', 'control', 'gave']].dropna()\n\ntreatment_group = df_binary[df_binary['treatment'] == 1]['gave']\ncontrol_group = df_binary[df_binary['control'] == 1]['gave']\n\n# Manual t-test calculation\nmean_diff = treatment_group.mean() - control_group.mean()\nn1, n2 = len(treatment_group), len(control_group)\nvar1, var2 = treatment_group.var(ddof=1), control_group.var(ddof=1)\nse = np.sqrt(var1 / n1 + var2 / n2)\nt_stat = mean_diff / se\ndf_denom = (var1 / n1 + var2 / n2) ** 2\ndf_num = (var1**2) / (n1**2 * (n1 - 1)) + (var2**2) / (n2**2 * (n2 - 1))\ndf_ttest = df_denom / df_num\np_value_ttest = 2 * (1 - stats.t.cdf(np.abs(t_stat), df_ttest))\n\n# Linear regression:\nX = sm.add_constant(df_binary['treatment'])\ny = df_binary['gave']\nmodel = sm.OLS(y, X).fit()\ncoef = model.params['treatment']\np_value_reg = model.pvalues['treatment']\n\nprint(\"================================================\")\nprint(f' \\'gave\\' Analysis: \\n')\nprint(f'\\'gave\\' Treatment mean: {treatment_group.mean()}')\nprint(f'\\'gave\\' Control mean: {control_group.mean()}')\nprint(f'Mean Difference: {mean_diff}')\nprint(f\"'gave' All mean: {df_binary['gave'].mean()}\")\nprint('________________________________________________')\nprint('t-test: \\n')\nprint(f't-statistic: {t_stat}')\nprint(f'p-value: {p_value_ttest}')\nprint('________________________________________________')\nprint('Linear Regression: \\n')\nprint(f'Coefficient on Treatment: {coef}')\nprint(f'p-value: {p_value_reg}')\n\n================================================\n 'gave' Analysis: \n\n'gave' Treatment mean: 0.02203856749311295\n'gave' Control mean: 0.017858212980164198\nMean Difference: 0.00418035451294875\n'gave' All mean: 0.020645728091368328\n________________________________________________\nt-test: \n\nt-statistic: 3.2094621908279835\np-value: 0.001330982345091547\n________________________________________________\nLinear Regression: \n\nCoefficient on Treatment: 0.004180354512949377\np-value: 0.001927402594901797\n\n\nTo test whether matched donations increase giving, I compared donation rates between the treatment and control groups using a t-test and a bivariate regression. The treatment group had a slightly higher donation rate (2.2% vs. 1.8%), and the difference was statistically significant in both tests. This matches results in Table 2A, Panel A of the original study and suggests that even a modest match offer can meaningfully boost donation rates. The finding highlights how small psychological nudges—like matching gifts—can influence charitable behavior.\n\nimport statsmodels.formula.api as smf\n\ndf_probit = df[['gave', 'treatment']].dropna()\n\nprobit_model = smf.probit('gave ~ treatment', data=df_probit).fit(disp=False)\n\nprobit_summary = probit_model.summary2().as_text()\n\nmarginal_effects = probit_model.get_margeff().summary().as_text()\n\nprint(marginal_effects)\n\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\ntreatment      0.0043      0.001      3.104      0.002       0.002       0.007\n==============================================================================\n\n\nTo replicate Table 3, Column 1 of Karlan and List (2007), I ran a probit regression with a binary outcome for donation and treatment assignment as the sole predictor. The marginal effect of treatment was 0.0043, closely matching the 0.004 reported in the paper. This confirms that the presence of a matching grant increased the probability of donating by roughly 0.4 percentage points, a statistically significant effect. While small in magnitude, the result reinforces the finding that subtle changes in perceived impact, such as matching gifts, can meaningfully influence donation behavior.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nfrom scipy.stats import ttest_ind\ndf_match = df[df['treatment'] == 1][['gave', 'ratio2', 'ratio3']].dropna()\n\n# Create labels for ratio group (1:1, 2:1, 3:1)\ndef classify_ratio(row):\n    if row['ratio2'] == 1:\n        return '2:1'\n    elif row['ratio3'] == 1:\n        return '3:1'\n    else:\n        return '1:1'\n\ndf_match['match_ratio'] = df_match.apply(classify_ratio, axis=1)\n\n# Pairwise t-tests between ratios\nratios = ['1:1', '2:1', '3:1']\npairwise_results = {}\n\nfor i in range(len(ratios)):\n    for j in range(i + 1, len(ratios)):\n        group1 = df_match[df_match['match_ratio'] == ratios[i]]['gave']\n        group2 = df_match[df_match['match_ratio'] == ratios[j]]['gave']\n        t_stat, p_value = ttest_ind(group1, group2, equal_var=False)\n        print(\"================================================\")\n        print(f'{ratios[i]} vs {ratios[j]}\\n')\n        print(f't-statistic: {t_stat}')\n        print(f'p-value: {p_value}\\n')\n\n================================================\n1:1 vs 2:1\n\nt-statistic: -0.965048975142932\np-value: 0.33453078237183076\n\n================================================\n1:1 vs 3:1\n\nt-statistic: -1.0150174470156275\np-value: 0.31010856527625774\n\n================================================\n2:1 vs 3:1\n\nt-statistic: -0.05011581369764474\np-value: 0.9600305476940865\n\n\n\nTo test whether the size of the match ratio influenced donation behavior, I conducted a series of pairwise t-tests comparing response rates between the 1:1, 2:1, and 3:1 match groups. None of the differences were statistically significant at the 95% level. For example, the difference between the 2:1 and 1:1 groups yielded a p-value of 0.33, and the difference between the 3:1 and 2:1 groups had a p-value of 0.96. These results support the authors’ statement in Table 2A and on page 8 of the paper: while match offers increase giving relative to no match, larger match ratios do not provide additional benefit in terms of increasing the likelihood of donating.\n\n# Alternative: use ratio as a categorical variable\nmodel2 = smf.ols('gave ~ ratio', data=df).fit()\nmodel2_summary = model2.summary2().as_text()\nprint(model2_summary)\n\n                  Results: Ordinary least squares\n====================================================================\nModel:              OLS              Adj. R-squared:     0.000      \nDependent Variable: gave             AIC:                -53252.8233\nDate:               2025-04-23 16:19 BIC:                -53217.5376\nNo. Observations:   50083            Log-Likelihood:     26630.     \nDf Model:           3                F-statistic:        3.665      \nDf Residuals:       50079            Prob (F-statistic): 0.0118     \nR-squared:          0.000            Scale:              0.020217   \n----------------------------------------------------------------------\n               Coef.    Std.Err.      t      P&gt;|t|     [0.025   0.975]\n----------------------------------------------------------------------\nIntercept      0.0179     0.0011   16.2245   0.0000    0.0157   0.0200\nratio[T.1]     0.0029     0.0017    1.6615   0.0966   -0.0005   0.0063\nratio[T.2]     0.0048     0.0017    2.7445   0.0061    0.0014   0.0082\nratio[T.3]     0.0049     0.0017    2.8016   0.0051    0.0015   0.0083\n--------------------------------------------------------------------\nOmnibus:             59812.754     Durbin-Watson:        2.005      \nProb(Omnibus):       0.000         Jarque-Bera (JB):     4316693.217\nSkew:                6.740         Prob(JB):             0.000      \nKurtosis:            46.438        Condition No.:        4          \n====================================================================\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors\nis correctly specified.\n\n\nTo test whether the match ratio affects donation behavior, I regressed the binary outcome gave on ratio as a categorical variable. Using the 1:1 match as the reference group, I found that the 2:1 and 3:1 match ratios had slightly higher donation rates, with coefficients of 0.0048 and 0.0049 respectively, both statistically significant at the 1% level. The 1:1 coefficient was smaller and not statistically significant. These results suggest that higher match ratios may slightly increase the likelihood of donating, although the effect is small in magnitude and inconsistent with earlier t-test results.\n\nresponse_rates = df_match.groupby('match_ratio')['gave'].mean()\n\ndiff_2v1_direct = response_rates['2:1'] - response_rates['1:1']\ndiff_3v2_direct = response_rates['3:1'] - response_rates['2:1']\n\ncoef_2v1_reg = model2.params['ratio[T.2]'] - model2.params['ratio[T.1]']\ncoef_3v2_reg = model2.params['ratio[T.3]'] - model2.params['ratio[T.2]']\n\nprint(\"Direct from data: \\n\")\nprint(f\"2:1 vs 1:1: {diff_2v1_direct}\")\nprint(f\"3:1 vs 2:1: {diff_3v2_direct}\")\nprint(\"================================================\")\nprint(\"From regression coefficients: \\n\")\nprint(f\"2:1 vs 1:1: {coef_2v1_reg}\")\nprint(f\"3:1 vs 2:1: {coef_3v2_reg}\")\n\nDirect from data: \n\n2:1 vs 1:1: 0.0018842510217149944\n3:1 vs 2:1: 0.00010002398025293902\n================================================\nFrom regression coefficients: \n\n2:1 vs 1:1: 0.0018842510217151158\n3:1 vs 2:1: 0.00010002398025313504\n\n\nTo assess whether larger match ratios increase the likelihood of donating, I calculated the differences in response rates both directly from the data and from regression coefficients. The results were nearly identical across both methods:\n\nThe difference between 2:1 and 1:1 was about 0.19 percentage points.\nThe difference between 3:1 and 2:1 was effectively zero.\nThe difference between 3:1 and 1:1 was again about 0.20 percentage points.\n\nThese findings confirm that while moving from a 1:1 to a 2:1 or 3:1 match may result in a small increase in donation likelihood, the differences are minimal and statistically weak. This supports the paper’s conclusion that larger match ratios do not meaningfully improve response rates beyond the effect of having a match at all.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\ndf_amount = df[['amount', 'treatment', 'control']].dropna()\n\ntreatment = df_amount[df_amount['treatment'] == 1]['amount']\ncontrol = df_amount[df_amount['control'] == 1]['amount']\nt_stat, p_value = stats.ttest_ind(treatment, control, equal_var=False)\nprint('T-test Results: ')\nprint('_______________________________')\nprint(f'T-statistic: {t_stat}\\nP-Value: {p_value}')\n\nT-test Results: \n_______________________________\nT-statistic: 1.9182618934467577\nP-Value: 0.055085665289183336\n\n\nI conducted a t-test to compare average donation amounts between the treatment and control groups. The test produced a t-statistic of 1.92 and a p-value of 0.055, which is just above the conventional 5 percent significance threshold. This suggests a weak, but not statistically significant, indication that the treatment may have increased donation amounts. While the result hints at a possible effect, it is not strong enough to draw a firm conclusion about the impact of matched donations on how much people give.\n\ndf_positive = df[df['amount'] &gt; 0]\n\ntreatment = df_positive[df_positive['treatment'] == 1]['amount']\ncontrol = df_positive[df_positive['control'] == 1]['amount']\nt_stat, p_value = stats.ttest_ind(treatment, control, equal_var=False)\nprint('T-test Results: ')\nprint('_______________________________')\nprint(f'T-statistic: {t_stat}\\nP-Value: {p_value}')\n\nT-test Results: \n_______________________________\nT-statistic: -0.5846089794983359\nP-Value: 0.5590471865673547\n\n\nTo analyze how much people donate conditional on giving, I restricted the data to respondents who made a donation and ran a t-test comparing donation amounts between treatment and control groups. The t-test produced a t-statistic of -0.58 and a p-value of 0.56, indicating no statistically significant difference in donation amounts. This suggests that while matched donations may influence whether someone gives, they do not affect how much donors give once they’ve decided to contribute. Because treatment was randomly assigned, the coefficient has a causal interpretation, but in this case, the effect size is negligible.\n\ndf_donated = df[df['amount'] &gt; 0]\n\ntreatment_donors = df_donated[df_donated['treatment'] == 1]['amount']\ncontrol_donors = df_donated[df_donated['control'] == 1]['amount']\n\ntreatment_mean = treatment_donors.mean()\ncontrol_mean = control_donors.mean()\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\n# Treatment histogram\naxes[0].hist(treatment_donors, bins=30, edgecolor='black')\naxes[0].axvline(treatment_mean, color='red', linestyle='dashed', linewidth=2)\naxes[0].set_title('Treatment Group')\naxes[0].set_xlabel('Donation Amount')\naxes[0].set_ylabel('Frequency')\naxes[0].annotate(f'Mean = ${treatment_mean:.2f}', xy=(treatment_mean, 10),\n                 xytext=(treatment_mean + 10, 20), arrowprops=dict(facecolor='red', arrowstyle='-&gt;'))\n\n# Control histogram\naxes[1].hist(control_donors, bins=30, edgecolor='black', color='orange')\naxes[1].axvline(control_mean, color='red', linestyle='dashed', linewidth=2)\naxes[1].set_title('Control Group')\naxes[1].set_xlabel('Donation Amount')\naxes[1].annotate(f'Mean = ${control_mean:.2f}', xy=(control_mean, 10),\n                 xytext=(control_mean + 10, 20), arrowprops=dict(facecolor='red', arrowstyle='-&gt;'))\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe histograms show the distribution of donation amounts among individuals who gave, separated by treatment group. Both distributions are right-skewed, with most donations concentrated at lower amounts. The red dashed lines mark the mean donation in each group: $43.87 for treatment and $45.54 for control. The similarity in means visually confirms earlier statistical results, indicating that while the presence of a match may influence whether someone donates, it does not significantly affect how much they give once they’ve decided to contribute."
  },
  {
    "objectID": "blog/hw1/hw1_questions.html#simulation-experiment",
    "href": "blog/hw1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nnp.random.seed(42)\n\n# Control group: Bernoulli(p=0.018), 100,000 draws\ncontrol_sim = np.random.binomial(n=1, p=0.018, size=100000)\n\n# Treatment group: Bernoulli(p=0.022), 10,000 draws\ntreatment_sim = np.random.binomial(n=1, p=0.022, size=10000)\n\n# diff_vector = treatment_sim - np.random.choice(control_sim, size=10000)\ndiff_vector = treatment_sim - control_sim[:10000]\n\ncumulative_avg = np.cumsum(diff_vector) / np.arange(1, len(diff_vector) + 1)\n\ntrue_diff = 0.022 - 0.018\n\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label='Cumulative Average of Differences')\nplt.axhline(y=true_diff, color='red', linestyle='--', label=f'True Difference = {true_diff:.3f}')\nplt.title('Law of Large Numbers: Cumulative Avg of Bernoulli Differences (Treatment - Control)')\nplt.xlabel('Number of Simulated Samples')\nplt.ylabel('Cumulative Average Difference')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis plot illustrates the Law of Large Numbers using simulated donation data. I calculated the cumulative average difference in donation rates between treatment (2.2 percent) and control (1.8 percent) groups across 10,000 simulated comparisons. The blue line shows how the average difference stabilizes, while the red dashed line marks the true difference (0.004). As more samples accumulate, the cumulative average converges to the true value, confirming that larger samples yield more reliable estimates.\n\n\nCentral Limit Theorem\n\nsample_sizes = [50, 200, 500, 1000]\nsimulations = 1000\np_control = 0.018\np_treatment = 0.022\n\ndiff_distributions = {}\n\nnp.random.seed(42)\n\nfor n in sample_sizes:\n    diffs = []\n    for _ in range(simulations):\n        control_draw = np.random.binomial(1, p_control, n)\n        treatment_draw = np.random.binomial(1, p_treatment, n)\n        mean_diff = treatment_draw.mean() - control_draw.mean()\n        diffs.append(mean_diff)\n    diff_distributions[n] = diffs\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    axes[i].hist(diff_distributions[n], bins=30, edgecolor='black', alpha=0.7)\n    axes[i].axvline(0, color='black', linestyle='--', label='Zero')\n    axes[i].set_title(f\"Sample Size = {n}\")\n    axes[i].set_xlabel(\"Mean Difference (Treatment - Control)\")\n    axes[i].axvline(p_treatment - p_control, color='red', linestyle='--', label='True Difference')\n    axes[i].set_ylabel(\"Frequency\")\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThese histograms show the distribution of average differences in donation rates between treatment and control groups across 1,000 simulations at sample sizes of 50, 200, 500, and 1000. At smaller sizes, the distributions are wide and zero (red) is near the center, reflecting high uncertainty. As the sample size grows, the distributions narrow and more centered around the true difference (black) and zero (red) moves toward the tail, making it less likely. This demonstrates the Central Limit Theorem and shows that larger samples improve our ability to detect small treatment effects."
  }
]